{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Description of the dataset üìù**\n*This dataset is created using offline augmentation from the original dataset.\nThis dataset consists of about 87K rgb images of healthy and diseased crop leaves which is categorized into 38 different classes.\nA new directory containing 33 test images is created later for prediction purpose.\n*\n* data at link: [https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset/data](http://)","metadata":{}},{"cell_type":"markdown","source":"# **Our goal üéØ**\n*Goal is clear and simple. We need to build a model, which can classify between healthy and diseased crop leaves and also if the crop have any disease, predict which disease is it.*","metadata":{}},{"cell_type":"markdown","source":"# Let's import required modules..\n\n","metadata":{}},{"cell_type":"code","source":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Import necessary libraries\nimport tensorflow as tf  # TensorFlow for machine learning tasks\nimport seaborn as sns    # Seaborn for statistical visualization\nimport matplotlib.pyplot as plt  # Matplotlib for plotting\nfrom tensorflow import keras     # Keras for building neural networks\nimport numpy as np      # NumPy for numerical computations\nimport os              # OS module for interacting with the operating system\nimport pandas as pd    # Pandas for data manipulation and analysis\nimport itertools       # Itertools for creating iterators\nfrom tensorflow.keras.utils import image_dataset_from_directory  # Utility for loading image datasets\nfrom tensorflow.keras.layers import BatchNormalization, Dropout   # Layers for neural networks\nfrom sklearn.metrics import precision_score, accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay  # Metrics for model evaluation\nfrom tensorflow.keras.preprocessing import image   # Utility for image preprocessing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T23:12:21.961894Z","iopub.execute_input":"2024-04-24T23:12:21.962211Z","iopub.status.idle":"2024-04-24T23:12:26.015206Z","shell.execute_reply.started":"2024-04-24T23:12:21.962163Z","shell.execute_reply":"2024-04-24T23:12:26.014402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploring the data üß≠**\n*note that data in kaggle exist and ready to use..*\n","metadata":{}},{"cell_type":"code","source":"#Loading the data..^_^\n\n# Define the paths to the training and validation datasets\ntrain_data = \"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\nvalid_data = \"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n\n# Load the training and validation dataset as an image dataset\ntrain_gen = image_dataset_from_directory(directory=train_data, image_size=(256, 256))\nvalid_gen = image_dataset_from_directory(directory=valid_data, image_size=(256, 256))\n\n# Normalize the pixel values of images in the training and validation dataset\ntrain_gen = train_gen.map(lambda image, label: (image / 255.0, label))\nvalid_gen = valid_gen.map(lambda image, label: (image / 255.0, label))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:26.020021Z","iopub.execute_input":"2024-04-24T23:12:26.020281Z","iopub.status.idle":"2024-04-24T23:12:47.374772Z","shell.execute_reply.started":"2024-04-24T23:12:26.020258Z","shell.execute_reply":"2024-04-24T23:12:47.373993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Our Classes^_^\n\n# Get the list of class names by listing directories in the training dataset\nclass_names = sorted(os.listdir(\"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"))\n# Print the total number of classes\nprint(f'The total number of classes is: {len(class_names)}')\n\n# Iterate through the class names and print each one\nfor class_name in class_names:\n    print(class_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:47.376093Z","iopub.execute_input":"2024-04-24T23:12:47.376448Z","iopub.status.idle":"2024-04-24T23:12:47.383161Z","shell.execute_reply.started":"2024-04-24T23:12:47.376411Z","shell.execute_reply":"2024-04-24T23:12:47.382082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify unique plants and count the number of diseases ^_^\n\n# Get the list of diseases by listing directories in the training data\ndiseases = os.listdir(train_data)\n# Initialize lists to store unique plants and count the number of diseases\nplants = []\nNumberOfDiseases = 0\n\n# Iterate through each disease\nfor plant in diseases:\n    # Check if the plant name is not already in the list of unique plants\n    if plant.split('_')[0] not in plants:\n        # Add the unique plant name to the list\n        plants.append(plant.split('_')[0])\n    # Check if the disease is not labeled as 'healthy'\n    if plant.split('_')[1] != 'healthy':\n        # Increment the count of diseases\n        NumberOfDiseases += 1\n\n# Print the number of unique plants in the dataset\nprint(\"Number of plants: {}\".format(len(plants)))\nprint('-'*50)\nprint(f\"Unique Plants are: \\n{plants}\")\nprint()\n\n# Print the number of unique diseases (excluding 'healthy')\nprint(\"Number of unique diseases (without healthy): {}\".format(NumberOfDiseases))\nprint('-'*50)\nprint(f\"Unique Plants are: \\n{diseases}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:47.385835Z","iopub.execute_input":"2024-04-24T23:12:47.386178Z","iopub.status.idle":"2024-04-24T23:12:47.394271Z","shell.execute_reply.started":"2024-04-24T23:12:47.386155Z","shell.execute_reply":"2024-04-24T23:12:47.393293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LOOK at shape of one photo :)\n\n# Define the path to the image file\nimport cv2\nimg_path = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Apple___Apple_scab/00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG\"\n# Read the image using OpenCV\nimg = cv2.imread(img_path)\n# Print the shape of the image\nprint(\"Image shape:\", img.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:47.395368Z","iopub.execute_input":"2024-04-24T23:12:47.395681Z","iopub.status.idle":"2024-04-24T23:12:47.432106Z","shell.execute_reply.started":"2024-04-24T23:12:47.395656Z","shell.execute_reply":"2024-04-24T23:12:47.431194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data visualization üìä**\n*some calculations of the data samples*","metadata":{}},{"cell_type":"code","source":"#Empty dictionaries to store count of images for each class in training and validation datasets ^_^\nnums_train = {}\nnums_valid = {}\n\n# Iterate over each disease in the list of diseases\nfor disease in diseases:\n    #Count and store number of images for the current disease in the training and validation dataset \n    nums_train[disease] = len(os.listdir(train_data+'/'+disease))\n    nums_valid[disease] = len(os.listdir(vaild_data+'/'+disease))\n\n# Create pandas DataFrames to display the count of images for each disease in the training and validation datasets\nimage_class_count_train = pd.DataFrame(nums_train.values(), index=nums_train.keys(), columns=['No. of images'])\nimage_class_count_valid = pd.DataFrame(nums_valid.values(), index=nums_valid.keys(), columns=['No. of images'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:47.433247Z","iopub.execute_input":"2024-04-24T23:12:47.433589Z","iopub.status.idle":"2024-04-24T23:12:47.516409Z","shell.execute_reply.started":"2024-04-24T23:12:47.433556Z","shell.execute_reply":"2024-04-24T23:12:47.515705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the count of training data images per class ^_^\nprint('Training data images count per class : ')\nprint(image_class_count_train)\n\n# Create a bar plot showing the count of training images per class\nplt.figure(figsize=(15,15))\nplt.title(\"Training data images count per class\",fontsize=38)\nplt.xlabel('Number of images', fontsize=35)\nplt.ylabel('Classes', fontsize=35)\n\n# Extract keys and values from the dictionary\nkeys = list(nums_train.keys())\nvals = list(nums_train.values())\n\n# Plot the bar plot using seaborn\nsns.barplot(y=keys, x=vals)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:47.517471Z","iopub.execute_input":"2024-04-24T23:12:47.517763Z","iopub.status.idle":"2024-04-24T23:12:48.551891Z","shell.execute_reply.started":"2024-04-24T23:12:47.51774Z","shell.execute_reply":"2024-04-24T23:12:48.550899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the count of validation data images per class ^_^\nprint('Validation data images count per class : ')\nprint(image_class_count_valid)\n\n# Create a bar plot showing the count of validation images per class\nplt.figure(figsize=(15,15))\nplt.title(\"Validation data images count per class\",fontsize=38)\nplt.xlabel('Number of images', fontsize=35)\nplt.ylabel('Classes', fontsize=35)\n\n# Extract keys and values from the dictionary\nkeys = list(nums_valid.keys())\nvals = list(nums_valid.values())\n\n# Plot the bar plot using seaborn\nsns.barplot(y=keys, x=vals)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:48.552894Z","iopub.execute_input":"2024-04-24T23:12:48.553158Z","iopub.status.idle":"2024-04-24T23:12:49.727443Z","shell.execute_reply.started":"2024-04-24T23:12:48.553135Z","shell.execute_reply":"2024-04-24T23:12:49.726512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize Images :)\n\nplt.figure(figsize=(40,30))#Set figure size to 40 inches in width and 30 inches in height\nplt.subplots_adjust(wspace=0.1,hspace=0.1)# width and height space between subplots to 0.1\n\n# Iterate over a range of 24 (to display 24 images)\nfor i in range(24):\n    #Get a random folder index within the range of available folders in the training data\n    random_folder = np.random.randint(0, len(os.listdir(train_data)))\n    #Get the path of the randomly selected folder\n    random_folder_path = os.path.join(train_data, os.listdir(train_data)[random_folder])  \n    #Get a random image index within the range of available images in the selected folder\n    random_image = np.random.randint(0, len(os.listdir(random_folder_path))) \n    \n    #Get the path of the randomly selected image and Read the image using OpenCV\n    random_image_path = os.path.join(random_folder_path, os.listdir(random_folder_path)[random_image])  \n    image = cv2.imread(random_image_path)  \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #Convert the image from (BGR to RGB) \n    \n    #Get the class name for the current image\n    class_name = class_names[random_folder]  \n    \n    # Create a subplot with 4 rows and 6 columns, and set the current subplot index\n    plt.subplot(4, 6, i + 1)  \n    plt.imshow(image)#Display the image\n    plt.axis(\"off\")#Turn off the axis\n    plt.title(class_name)#Set the title of the subplot to the class name  \n    \n# Display the entire plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:49.728652Z","iopub.execute_input":"2024-04-24T23:12:49.728938Z","iopub.status.idle":"2024-04-24T23:12:55.511309Z","shell.execute_reply.started":"2024-04-24T23:12:49.728913Z","shell.execute_reply":"2024-04-24T23:12:55.509581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modelling üèóÔ∏è**\n* *It is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized for general purpose and GPUs are optimized for training deep learning models as they can process multiple computations simultaneously.*\n* *They have a large number of cores, which allows for better computation of multiple parallel processes.*\n* *Additionally, computations in deep learning need to handle huge amounts of data, this makes a GPU‚Äôs memory bandwidth most suitable.*","metadata":{}},{"cell_type":"markdown","source":"# **Building the model architecture üë∑**\n*We are going to use CNN..*","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential()\n\nmodel.add(keras.layers.Conv2D(32,(3,3),activation=\"relu\",padding=\"same\",input_shape=(256,256,3)))\nmodel.add(keras.layers.Conv2D(32,(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(keras.layers.MaxPooling2D(3,3))\nmodel.add(BatchNormalization())\n\nmodel.add(keras.layers.Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(keras.layers.Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(keras.layers.MaxPooling2D(3,3))\n\nmodel.add(keras.layers.Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(keras.layers.Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(keras.layers.MaxPooling2D(3,3))\nmodel.add(BatchNormalization())\n\nmodel.add(keras.layers.Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(keras.layers.Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\n\nmodel.add(keras.layers.Conv2D(512,(5,5),activation=\"relu\",padding=\"same\"))\nmodel.add(keras.layers.Conv2D(512,(5,5),activation=\"relu\",padding=\"same\"))\n\nmodel.add(keras.layers.Flatten())\n\nmodel.add(keras.layers.Dense(1568,activation=\"relu\"))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(keras.layers.Dense(38,activation=\"softmax\"))\n\nopt = keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer=opt,loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:55.513418Z","iopub.execute_input":"2024-04-24T23:12:55.513776Z","iopub.status.idle":"2024-04-24T23:12:55.875181Z","shell.execute_reply.started":"2024-04-24T23:12:55.513749Z","shell.execute_reply":"2024-04-24T23:12:55.874252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training the model.. üèãÔ∏è**","metadata":{}},{"cell_type":"code","source":"# Train the model on the training data and validate it on the validation data ^_^\nhistory = model.fit(\n    train_gen,  # Training data generator\n    validation_data=vaild_gen,  # Validation data generator\n    epochs=10  # Number of epochs for training\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T23:12:55.876278Z","iopub.execute_input":"2024-04-24T23:12:55.876589Z","iopub.status.idle":"2024-04-25T00:18:20.898952Z","shell.execute_reply.started":"2024-04-24T23:12:55.876562Z","shell.execute_reply":"2024-04-25T00:18:20.898057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Plotting üìà**\n*plots it will make my model easy to understand characteristics of it..*","metadata":{}},{"cell_type":"code","source":"# Plotting the training and validation loss and accuracy ^_^\nplt.figure(figsize=(20, 5))\n\n# Subplot for training and validation loss\nplt.subplot(1, 2, 1)\nplt.title(\"Train and Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.plot(history.history['loss'], label=\"Train Loss\")\nplt.plot(history.history['val_loss'], label=\"Validation Loss\")\nplt.xlim(0, 10)\nplt.ylim(0.0, 1.0)\nplt.legend()\n\n# Subplot for training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.title(\"Train and Validation Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.plot(history.history['accuracy'], label=\"Train Accuracy\")\nplt.plot(history.history['val_accuracy'], label=\"Validation Accuracy\")\nplt.xlim(0, 9.25)\nplt.ylim(0.75, 1.0)\nplt.legend()\n\nplt.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T00:18:20.900231Z","iopub.execute_input":"2024-04-25T00:18:20.900548Z","iopub.status.idle":"2024-04-25T00:18:21.632588Z","shell.execute_reply.started":"2024-04-25T00:18:20.900508Z","shell.execute_reply":"2024-04-25T00:18:21.631404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obtain and Flatten Labels and Predictions for Validation Data ^_^\nimport tensorflow as tf\nimport itertools\n\n# Initialize lists to store labels and predictions\nlabels = []\npredictions = []\n\n# Iterate over the validation generator to get labels and predictions\nfor x, y in vaild_gen:\n    labels.append(list(y.numpy()))#Append true labels\n    predictions.append(tf.argmax(model.predict(x), 1).numpy())#Append predicted labels\n\n# Flatten the lists of lists\npredictions = list(itertools.chain.from_iterable(predictions))\nlabels = list(itertools.chain.from_iterable(labels))\n   \n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T00:31:47.923438Z","iopub.execute_input":"2024-04-25T00:31:47.924411Z","iopub.status.idle":"2024-04-25T00:32:49.581107Z","shell.execute_reply.started":"2024-04-25T00:31:47.924375Z","shell.execute_reply":"2024-04-25T00:32:49.580368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Display model performance :) üìã**","metadata":{}},{"cell_type":"code","source":"# Print evaluation metrics based on the model's performance ^_^\n#All multiplied by 100 and formatted to two decimal places.\n\n#Train Accuracy: retrieves the last recorded training accuracy from the training history\nprint(\"Train Accuracy: {:.2f} %\".format(history.history['accuracy'][-1]*100))\n\n#Test Accuracy: computes accuracy score by comparing true labels with predicted labels\nprint(\"Test Accuracy: {:.2f} %\".format(accuracy_score(labels, predictions) * 100))\n\n#Precision Score: computes the precision score using the micro averaging strategy.\nprint(\"Precision Score: {:.2f} %\".format(precision_score(labels, predictions, average='micro') * 100))\n\n#Recall Score: computes the recall score using the micro averaging strategy\nprint(\"Recall Score: {:.2f} %\".format(recall_score(labels, predictions, average='micro') * 100))","metadata":{"execution":{"iopub.status.busy":"2024-04-25T00:34:54.308623Z","iopub.execute_input":"2024-04-25T00:34:54.309011Z","iopub.status.idle":"2024-04-25T00:34:54.367466Z","shell.execute_reply.started":"2024-04-25T00:34:54.308985Z","shell.execute_reply":"2024-04-25T00:34:54.366562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# confusion matrix ..üßÆ","metadata":{}},{"cell_type":"code","source":"# Plot a confusion matrix based on the true labels and predicted labels ^_^\nplt.figure(figsize= (20,5))\ncm = confusion_matrix(labels, predictions)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(1,39)))\nfig, ax = plt.subplots(figsize=(12,12))\ndisp.plot(ax=ax,colorbar= False,cmap = 'YlGnBu')\nplt.title(\"Confusion Matrix\")\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T01:00:11.238694Z","iopub.execute_input":"2024-04-25T01:00:11.239496Z","iopub.status.idle":"2024-04-25T01:00:14.634554Z","shell.execute_reply.started":"2024-04-25T01:00:11.239463Z","shell.execute_reply":"2024-04-25T01:00:14.633573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualize and predict one image :)","metadata":{}},{"cell_type":"code","source":"#prepare the image, make it ready to be predicted bu the model ^_^\n\n# Load and preprocess the image\nfrom tensorflow.keras.preprocessing import image\nimg_path = '/kaggle/input/new-plant-diseases-dataset/test/test/AppleCedarRust1.JPG'\nimg = image.load_img(img_path, target_size=(256,256))\nimg_array = image.img_to_array(img)\nimg_array = img_array.astype(\"float32\") / 255.0 \nimg_array = tf.expand_dims(img_array, 0)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T01:01:44.873429Z","iopub.execute_input":"2024-04-25T01:01:44.873873Z","iopub.status.idle":"2024-04-25T01:01:44.91561Z","shell.execute_reply.started":"2024-04-25T01:01:44.87384Z","shell.execute_reply":"2024-04-25T01:01:44.914489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize your image using function load_prep ^_^\ndef load_prep(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_image(img)\n    img = tf.image.resize(img, size=(224,224))\n    return img\n\n# Load and preprocess the image\nimage = load_prep(img_path)\n\n# Visualize the preprocessed image\nplt.imshow(image/255.)\nplt.title('AppleCedarRust1.JPG')\nplt.suptitle(image.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T01:02:19.048393Z","iopub.execute_input":"2024-04-25T01:02:19.04907Z","iopub.status.idle":"2024-04-25T01:02:19.387697Z","shell.execute_reply.started":"2024-04-25T01:02:19.049036Z","shell.execute_reply":"2024-04-25T01:02:19.386797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(img_array)\npredictions","metadata":{"execution":{"iopub.status.busy":"2024-04-25T01:02:37.541733Z","iopub.execute_input":"2024-04-25T01:02:37.542128Z","iopub.status.idle":"2024-04-25T01:02:40.035431Z","shell.execute_reply.started":"2024-04-25T01:02:37.542096Z","shell.execute_reply":"2024-04-25T01:02:40.034545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_class = np.argmax(predictions)\nprint(f\"this image : Predicted Class: {predicted_class}, Class name: {class_names[predicted_class]}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T01:03:08.090521Z","iopub.execute_input":"2024-04-25T01:03:08.091229Z","iopub.status.idle":"2024-04-25T01:03:08.096128Z","shell.execute_reply.started":"2024-04-25T01:03:08.091198Z","shell.execute_reply":"2024-04-25T01:03:08.09512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Testing model on test data üß™**\n*here we go to the test directory prepare it to apply our model on it let's see :)*\n","metadata":{}},{"cell_type":"code","source":"# Predict plant diseases for each image in the test directory ^_^\nfrom tensorflow.keras.preprocessing import image\nimages_dir =\"/kaggle/input/new-plant-diseases-dataset/test/test\"\n\n# Iterate through each image in the directory\nimage_files = os.listdir(images_dir)\nfor img_file in image_files:\n    # Construct the full path to the image\n    img_path = os.path.join(images_dir, img_file)\n    \n    # Load the image and preprocess it\n    img = image.load_img(img_path, target_size=(256, 256))\n    img_array = image.img_to_array(img)\n    img_array = img_array.astype(\"float32\") / 255.0\n    img_array_batch = np.expand_dims(img_array, axis=0)\n    \n    # Make predictions using the model\n    predictions = model.predict(img_array_batch)\n    predicted_class = np.argmax(predictions)\n    \n    # Print the prediction results\n    print(f\"Image: {img_file}, Predicted Class: {predicted_class}, Class name: {class_names[predicted_class]}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T01:05:27.078474Z","iopub.execute_input":"2024-04-25T01:05:27.079458Z","iopub.status.idle":"2024-04-25T01:05:29.411998Z","shell.execute_reply.started":"2024-04-25T01:05:27.079423Z","shell.execute_reply":"2024-04-25T01:05:29.411039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize random images with their predicted classes..üçÄ\n note that you can increase number of images to br predicted and change style of display..","metadata":{}},{"cell_type":"code","source":"# Create a figure to display the images ^_^\nfrom tensorflow.keras.preprocessing import image\nimport random \nplt.figure(figsize=(20,20))\n\n# Iterate through 9 random images\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    \n    # Select a random image from the directory\n    rn = random.choice(os.listdir(images_dir))\n    img_path = os.path.join(images_dir, rn)\n    \n    # Preprocess the image\n    new_img = load_prep(img_path)\n    \n    # Load and preprocess the image for prediction\n    photo = image.load_img(img_path, target_size=(256,256))  \n    photo_array = image.img_to_array(photo)\n    photo_array = photo_array.astype(\"float32\") / 255.0 \n    photo_array = tf.expand_dims(photo_array, 0) \n    predictions_photo_array = model.predict(photo_array)\n    pred_class_ = np.argmax(predictions_photo_array)\n    \n    # Display the image and its predicted class\n    plt.imshow(new_img/255.)\n    plt.title(f'true:{rn} \\npred_class:{pred_class_} \\nClassname: {class_names[pred_class_]}')\n    plt.axis(False)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T01:07:56.373834Z","iopub.execute_input":"2024-04-25T01:07:56.374229Z","iopub.status.idle":"2024-04-25T01:07:59.391612Z","shell.execute_reply.started":"2024-04-25T01:07:56.374199Z","shell.execute_reply":"2024-04-25T01:07:59.390086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Finally..Saving our model üìÇ**","metadata":{}},{"cell_type":"code","source":"# save it as a h5 file ^_^\nfrom tensorflow.keras.models import load_model\nmodel.save('model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T01:17:37.411548Z","iopub.execute_input":"2024-04-25T01:17:37.411969Z","iopub.status.idle":"2024-04-25T01:17:39.1771Z","shell.execute_reply.started":"2024-04-25T01:17:37.411938Z","shell.execute_reply":"2024-04-25T01:17:39.17623Z"},"trusted":true},"execution_count":null,"outputs":[]}]}